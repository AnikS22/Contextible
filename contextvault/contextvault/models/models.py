"""SQLAlchemy models for AI model management."""

import json
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional

from sqlalchemy import JSON, DateTime, String, Text, func, Boolean, Float, Integer
from sqlalchemy.orm import Mapped, mapped_column

from ..database import Base


class ModelProvider(str, Enum):
    """Enumeration of AI model providers."""
    OLLAMA = "ollama"
    LM_STUDIO = "lmstudio"
    JAN_AI = "jan_ai"
    LOCALAI = "localai"
    GPT4ALL = "gpt4all"
    OPENAI = "openai"
    ANTHROPIC = "anthropic"


class ModelStatus(str, Enum):
    """Enumeration of model statuses."""
    ACTIVE = "active"
    INACTIVE = "inactive"
    ERROR = "error"
    UNAVAILABLE = "unavailable"


class AIModel(Base):
    """
    Model for storing AI model information and capabilities.
    
    Tracks different AI models, their capabilities, performance metrics,
    and configuration for intelligent routing and management.
    """
    
    __tablename__ = "ai_models"
    
    # Primary identifier
    id: Mapped[str] = mapped_column(
        String(36), 
        primary_key=True, 
        default=lambda: str(uuid.uuid4()),
        comment="Unique identifier for the AI model"
    )
    
    # Basic model information
    name: Mapped[str] = mapped_column(
        String(255), 
        nullable=False,
        comment="Model name (e.g., 'llama2', 'mistral', 'codellama')"
    )
    
    display_name: Mapped[Optional[str]] = mapped_column(
        String(255), 
        nullable=True,
        comment="Human-readable display name"
    )
    
    provider: Mapped[ModelProvider] = mapped_column(
        nullable=False,
        comment="AI model provider (ollama, lmstudio, jan_ai, etc.)"
    )
    
    model_id: Mapped[str] = mapped_column(
        String(255), 
        nullable=False,
        index=True,
        comment="Provider-specific model identifier"
    )
    
    # Model capabilities and characteristics
    capabilities: Mapped[Optional[Dict[str, Any]]] = mapped_column(
        JSON, 
        nullable=True, 
        default=dict,
        comment="Model capabilities (coding, creative, analysis, etc.)"
    )
    
    max_context_length: Mapped[int] = mapped_column(
        Integer, 
        default=4096,
        comment="Maximum context length this model can handle"
    )
    
    max_tokens: Mapped[int] = mapped_column(
        Integer, 
        default=2048,
        comment="Maximum tokens this model can generate"
    )
    
    # Performance and status
    status: Mapped[ModelStatus] = mapped_column(
        nullable=False,
        default=ModelStatus.ACTIVE,
        comment="Current status of the model"
    )
    
    is_active: Mapped[bool] = mapped_column(
        Boolean, 
        default=True,
        comment="Whether this model is currently active"
    )
    
    # Configuration
    endpoint: Mapped[Optional[str]] = mapped_column(
        String(500), 
        nullable=True,
        comment="API endpoint for this model"
    )
    
    api_key: Mapped[Optional[str]] = mapped_column(
        String(500), 
        nullable=True,
        comment="API key for this model (encrypted)"
    )
    
    configuration: Mapped[Optional[Dict[str, Any]]] = mapped_column(
        JSON, 
        nullable=True, 
        default=dict,
        comment="Model-specific configuration"
    )
    
    # Performance metrics
    performance_metrics: Mapped[Optional[Dict[str, Any]]] = mapped_column(
        JSON, 
        nullable=True, 
        default=dict,
        comment="Performance metrics (response time, accuracy, etc.)"
    )
    
    average_response_time_ms: Mapped[Optional[int]] = mapped_column(
        Integer, 
        nullable=True,
        comment="Average response time in milliseconds"
    )
    
    success_rate: Mapped[Optional[float]] = mapped_column(
        Float, 
        nullable=True,
        comment="Success rate (0.0-1.0)"
    )
    
    # Usage tracking
    total_requests: Mapped[int] = mapped_column(
        Integer, 
        default=0,
        comment="Total number of requests processed"
    )
    
    total_tokens_generated: Mapped[int] = mapped_column(
        Integer, 
        default=0,
        comment="Total tokens generated by this model"
    )
    
    last_used_at: Mapped[Optional[datetime]] = mapped_column(
        DateTime(timezone=True), 
        nullable=True,
        comment="When this model was last used"
    )
    
    # Metadata
    description: Mapped[Optional[str]] = mapped_column(
        Text, 
        nullable=True,
        comment="Description of this model"
    )
    
    tags: Mapped[Optional[List[str]]] = mapped_column(
        JSON, 
        nullable=True, 
        default=list,
        comment="Tags for categorization"
    )
    
    # Timestamps
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), 
        server_default=func.now(),
        comment="When the model was added"
    )
    
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), 
        server_default=func.now(), 
        onupdate=func.now(),
        comment="When the model was last updated"
    )
    
    def __repr__(self) -> str:
        """String representation of the model."""
        return (
            f"<AIModel(id='{self.id}', "
            f"name='{self.name}', "
            f"provider='{self.provider}', "
            f"status='{self.status}')>"
        )
    
    def to_dict(self, include_sensitive: bool = False) -> Dict[str, Any]:
        """
        Convert the model to a dictionary.
        
        Args:
            include_sensitive: Whether to include sensitive information like API keys
            
        Returns:
            Dictionary representation of the model
        """
        result = {
            "id": self.id,
            "name": self.name,
            "display_name": self.display_name,
            "provider": self.provider.value if hasattr(self.provider, 'value') else str(self.provider),
            "model_id": self.model_id,
            "capabilities": self.capabilities or {},
            "max_context_length": self.max_context_length,
            "max_tokens": self.max_tokens,
            "status": self.status.value if hasattr(self.status, 'value') else str(self.status),
            "is_active": self.is_active,
            "endpoint": self.endpoint,
            "configuration": self.configuration or {},
            "performance_metrics": self.performance_metrics or {},
            "average_response_time_ms": self.average_response_time_ms,
            "success_rate": self.success_rate,
            "total_requests": self.total_requests,
            "total_tokens_generated": self.total_tokens_generated,
            "description": self.description,
            "tags": self.tags or [],
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None,
            "last_used_at": self.last_used_at.isoformat() if self.last_used_at else None,
        }
        
        if include_sensitive:
            result["api_key"] = self.api_key
        
        return result
    
    def get_capability_score(self, capability: str) -> float:
        """Get the capability score for a specific capability."""
        if not self.capabilities:
            return 0.0
        
        return self.capabilities.get(capability, {}).get("score", 0.0)
    
    def has_capability(self, capability: str) -> bool:
        """Check if this model has a specific capability."""
        if not self.capabilities:
            return False
        
        return capability in self.capabilities and self.capabilities[capability].get("score", 0.0) > 0.0
    
    def update_performance_metrics(self, 
                                 response_time_ms: int, 
                                 success: bool, 
                                 tokens_generated: int = 0) -> None:
        """Update performance metrics for this model."""
        self.total_requests += 1
        self.total_tokens_generated += tokens_generated
        self.last_used_at = datetime.utcnow()
        
        # Update average response time
        if self.average_response_time_ms is None:
            self.average_response_time_ms = response_time_ms
        else:
            # Exponential moving average
            alpha = 0.1
            self.average_response_time_ms = int(
                alpha * response_time_ms + (1 - alpha) * self.average_response_time_ms
            )
        
        # Update success rate
        if self.success_rate is None:
            self.success_rate = 1.0 if success else 0.0
        else:
            # Exponential moving average
            alpha = 0.1
            success_value = 1.0 if success else 0.0
            self.success_rate = alpha * success_value + (1 - alpha) * self.success_rate
        
        # Update performance metrics
        if not self.performance_metrics:
            self.performance_metrics = {}
        
        self.performance_metrics.update({
            "last_response_time_ms": response_time_ms,
            "last_success": success,
            "last_tokens_generated": tokens_generated,
            "updated_at": datetime.utcnow().isoformat()
        })
    
    def is_healthy(self) -> bool:
        """Check if this model is healthy and available."""
        if not self.is_active or self.status != ModelStatus.ACTIVE:
            return False
        
        # Check if model has been used recently (within last hour)
        if self.last_used_at:
            time_since_last_use = datetime.utcnow() - self.last_used_at
            if time_since_last_use.total_seconds() > 3600:  # 1 hour
                # If not used recently, we can't determine health
                return True
        
        # Check success rate
        if self.success_rate is not None and self.success_rate < 0.5:
            return False
        
        return True
    
    def get_health_score(self) -> float:
        """Get a health score for this model (0.0-1.0)."""
        if not self.is_active or self.status != ModelStatus.ACTIVE:
            return 0.0
        
        score = 1.0
        
        # Penalize for low success rate
        if self.success_rate is not None:
            score *= self.success_rate
        
        # Penalize for high response time
        if self.average_response_time_ms is not None:
            # Penalize if response time is over 10 seconds
            if self.average_response_time_ms > 10000:
                score *= 0.5
            elif self.average_response_time_ms > 5000:
                score *= 0.8
        
        return score
    
    @classmethod
    def create_model(cls, 
                    name: str,
                    provider: ModelProvider,
                    model_id: str,
                    capabilities: Optional[Dict[str, Any]] = None,
                    endpoint: Optional[str] = None,
                    **kwargs) -> "AIModel":
        """
        Create a new AI model instance.
        
        Args:
            name: Model name
            provider: Model provider
            model_id: Provider-specific model ID
            capabilities: Model capabilities
            endpoint: API endpoint
            **kwargs: Additional model parameters
            
        Returns:
            New AIModel instance
        """
        return cls(
            name=name,
            provider=provider,
            model_id=model_id,
            capabilities=capabilities or {},
            endpoint=endpoint,
            **kwargs
        )
